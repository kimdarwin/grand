{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65de98a2-9872-420e-830d-d52dbca151c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "5/27983 15.초\n",
      "Question: 영덕군 영해면 성내\n",
      "[1]   농촌현장포럼 결과보고서영덕 예주고을(박승배 사무장)1. 예주권역의 마을 종합개발사업의 시작 예주권역 거점면소재지 마을종합개발사업은 총사업비 70억원(국비 49억원, 지방비 21억원)으로 오는 12월까지 예주생활관, 한마음광장, 등산로정비, 중심상가주차장, 삼각주공원, 담장정비 및 컨설팅, 홍보 마케팅, 교육, 정보화 사업 등 핵심사업구역을 지정해 사업이 (유사도: 0.5859)\n",
      "[2] 함께하는 우리 농촌 운동절의 고장이며, 고려조의 대 사상가(성리학)이자 훌륭한 재상으로써 불사이군의 충절과 고려 문학을 대표하는 대 문인인 목은 이색선생을 배출한 곳이기도 합니다. 예주문화예술회관과 생활체육공원, 3.1의거탑, 이색목은기념관 등이 있으며, 이를 중심으로 괴시리 전통마을 등 유교문화권사업이 완성되면 전통문화와 충절을 배우는 산 교육의 장으로  (유사도: 0.5858)\n",
      "[3]   농촌현장포럼 결과보고서 현장견학지 소개영덕옥계권역(이민석 위원장)영덕 옥계권역 농촌마을종합개발사업 개요 1. 위      치 : 경상북도영덕군 달산면 옥산리, 주응리, 흥기리2. 규      모 : 3개 법정리, 6개 행정리 (옥산1,2,3리, 주응1,2리, 흥기3리) 3. 면      적 : 1,935.8ha (농경지: 112.8ha, 임야: 1,82 (유사도: 0.5583)\n",
      "\n",
      "\n",
      "10/27983 13.초\n",
      "Question: ‘Halla Gold’) 같은 골드키위들이 계속해서 육성 보급되는 계기가 되었다(Kim \n",
      "[1] 녹색인 그린키위 밖에 없었기 때문에 국내에서도 ‘헤이워드’ 품종을 대체할 수 있는 품종개발에대한 연구만이 진행되었다(김, 2014). 1990년대에 농촌진흥청 국립원예특작과학원을 중심으로 교잡육종을 통하여 ‘보옥’, ‘제시그린’, ‘제시스위트’ 및 ‘보화’ 품종이 육성되었으나 농가재배는 극히 일부에서 이루지고 있다(Kim et al., 2007b; 국립종자 (유사도: 0.6030)\n",
      "[2] 성과 세부 성과물성과물 성과물적용 세부과제명 과제 승인여유형 성과물명 주담당자년월 책임자 부2015년 조중생 참다래 품종 골드키위 재배농가에 희소식, 골드김성철 홍보 김성철 승인2월 육성및유전자원수집 키위 하우스 가운데 심어야(5.0)2015년 국산 골드키위 비가림하우스 재〃 〃 〃 〃 승인1월 배 어디에심을까(5.2)2015년 농진청 골드키위 일자형 수형 (유사도: 0.5950)\n",
      "[3] 육성 수집연도 계통명 품종명 특 성 도입형태 비고국가 지역2013 A. chinensis 화유 중국 중국 고당도, 황색과 종자A. chinensis 뉴골드브리드 뉴질랜드 한국 고당도, 골드 접수2014A. chinensis 엔자골드 뉴질랜드 한국 고당도, 골드 접수A. chinensis 엔자레드 뉴질랜드 한국 고당도, 레드 접수2015A. deliciosa (유사도: 0.5592)\n",
      "\n",
      "\n",
      "15/27983 17.초\n",
      "Question: 이 때 추출되는 개체 타입은 11개로 GE(gene\n",
      "[1] ◦ 개체명 인식기법 연구1) 생물학 개체명 인식 기법 연구가) PubMed NER Annotation 결과 제공 시스템- 1단계에서 개발된 개체명 인식 기법을 통해 추출된 결과를 웹에서 확인할 수 있는 시스템을 개발하였다. 개체명 인식 대상이 되는 MEDLINE 데이터는 FTP 서버를 통해 가장 최근 업데이트 된 버전을 활용하여 결과적으로 1,028개의 X (유사도: 0.5870)\n",
      "[2] 용관계로 확장한 이형 네트워크- 본 연구에서 시드 개체는 유전자 ‘apoA5’로 정의한다. Sequence 간 유사도를 찾아주는 툴인 BLAST[9](Basic Local Alignment Search Tool)을 사용하여 ‘apoA5’와 유사한 gene sequence를 가지고 있는 유전자로 개체 리스트를 구성하였다[표 2]. (유사도: 0.5653)\n",
      "[3] - 추출된 개체관계를 10개의 관계 타입으로 자동 분류하는 모델을 구현하기 위해 기존 파이프라인 시스템을 통해 PubMed 초록에서 추출된 개체관계 후보군을 10개의 타입으로 수작업 분류하는 작업을 수행하여 멀티타입 생물학 개체관계 코퍼스를 구축하였다.- 10개의 관계타입: Directed Link, Undirected Link, Positive Cause (유사도: 0.5560)\n",
      "\n",
      "\n",
      "20/27983 8.7초\n",
      "Question: 뇌척수액 ELISPOT 검사를 다른 검사(뇌척수액 그람염색과 cryptococcal latex agglutination test)와 함께 사용할 \n",
      "[1] 구분 5월 6월 7월 8월 9월 10월 11월 12월결핵성 뇌수막염 의심 환자의 혈액‧뇌척수액 검체 수집진단시 뇌척수액 및 말초혈액 ELISPOT 검사에 관한 연구치료 시작 후 말초 혈액 추적 ELISPOT 검사에 관한 연구ELISPOT 검사의 결과 판독을 점검ELISPOT 검사의 적절 cut-off value 결정ELISPOT 검사를 통한 진단 모델 개발 (유사도: 0.8430)\n",
      "[2] ○ 따라서, 말초 혈액 ELISPOT 검사의 추적은 결핵성 뇌수막염 치료 반응을 예측에는 제한점이 있음.4-3 결과 고찰 및 결론○ 본 연구에서 뇌척수액 ELISPOT 검사의 결핵성 뇌수막염 진단에 대한 예민도는 72%,특이도는 82%로 결핵성 뇌수막염의 신속 진단에 유용함.○ 결핵성 뇌수막염의 높은 사망률과 합병증을 감안할 때, 예민도 72%는 결핵성 뇌 (유사도: 0.8322)\n",
      "[3] Figure 1. Box-and-whisker plot showing responses to early secretory antigenictarget-6 (ESAT-6) and culture filtrate protein-10 (CFP-10), according to theperipheral blood and cerebrospinal fluid mononu (유사도: 0.8197)\n",
      "\n",
      "\n",
      "25/27983 30.초\n",
      "Question: 실무팀 자격 : 수의학교\n",
      "[1] 2011년 세계동물보건기구(OIE)는 회원국 수의학교육의 질이 국제 기준 이 하이며 수의과대학은 사회가 요구하는 동물건강, 식품안전성, 동물복지 등 주요 분야에 관한 최소한의 지식을 가르쳐야 한다고 하였다. 국제적으로 수 의학 교육의 질을 높이기 위하여, 수의서비스를 제공할 수 있는 최소한 요 구사항 (core curriculum), 수의사의 국제적 이동을 (유사도: 0.7724)\n",
      "[2] 다.일본 농림수산성은 수의사국가시험 출제기 준을 1999년 발간하였으며, 수의 사국가시험에서 수의학 이론과 실기를 구 교과목중심의 17개 시험과목을4개 시험과목으로 개정하여 평가하고 있다. 수의과대학을 졸업 한 학생이 졸업 후 1일차에 무엇을 할 수 있어야 할 것인지는 Day 1 skills라고 부르 며, 미국, 영국, EU는 이에 대한 문서화된 구체적 기 (유사도: 0.7328)\n",
      "[3] * 관련 : 수의사법 제8조, 수의사법 시행령 제4조, 제11조3. 사회가 요구하는 수의서비스 인력양성이 필요합니다.□  교육프로그램 : 수의서비스 수요에 따른 주제별 학부프로그램.주관 대학 선정과 장기 계약기간 중 재정지원□  서비스 예시 : 산업동물질병, 인수공통전염병, 동물성식품위생,바이오시 밀 러 동등성 평가, 수의 사연수교육과 연계.□  교육 질  (유사도: 0.7303)\n",
      "\n",
      "\n",
      "30/27983 18.초\n",
      "Question: 빵부피는 국산밀 품종에 따라 비교적 큰 차이를 보였는\n",
      "[1] 글루텐특성(%) 호화점도(B.U.)GI WGC DGC WB 최고점도 breakdown setbackHRS 91.00 34.45 11.85 22.6 323 98 264CWRS 82.40 35.25 11.75 23.5 287 73 221조경 98.11 18.05 6.15 11.9 255 42 190금강 94.57 28.55 9.90 18.65 312 67 29 (유사도: 0.7336)\n",
      "[2] < 시험 2 > 단백질 함량에 따른 빵용 블랜딩 밀가루 품질 및 가공 특성(1) 농가산 밀 품종의 단백질 함량에 따른 밀가루 품질 특성(표 1)지역의 농가에서 수집한 밀 품종의 단백질함량이 각 농가의 재배 형태에 따라서 변이를 보였는데, 조경밀은 11～14%, 금강밀은 12～15% 정도의 차이를 보였다. 농가에 따라 단백질 함량에서 차이를 보이기 때문에 같 (유사도: 0.7285)\n",
      "[3] HRS+조품4% HRS+조품8% HRS+조품12% HRS+조품16% HRS+조품20%< 시험 2 > 국산 밀 품종과 수입밀(DNS) 블랜딩에 의한 빵용 밀가루 품질 및 식빵 특성(1) 수입밀 DNS에 조경밀을 최대 30% 대체한 빵용 블랜딩밀가루 특성(표 1)수입 미국산 DNS(dark northern spring)는 대표적인 빵용 밀가루로 조경밀을 5～3 (유사도: 0.7192)\n",
      "\n",
      "\n",
      "35/27983 17.초\n",
      "Question: 국산 밀 품종별 식빵부피는 조경밀 775 \n",
      "[1] 8 37.3 2001 65 3.52 144 81212 39.0 1892 65 3.55 144 78716 42.6 2145 65 3.55 145 78720 40.9 2086 65 3.76 145 755(7) 수입밀(HRS)에 국산밀 품종을 대체한 혼합분 식빵 품질 및 식미검증(표 7)수입밀 HRS에 조경밀 4%와 8% 블랜딩한 식빵 속질(bread crumb (유사도: 0.7274)\n",
      "[2] 국산 밀 품종 활용 식빵 가공 시, 단일 품종보다는 2～3개 품종을 혼합한 밀가루를 사용했을 때 식빵 품질을 향상시킬 수 있는 것으로 나타났다. 혼합밀가루를 위한 적합 비율은,조경밀+금강밀+조품밀(각 33%) 혼합밀가루가 가장 우수하였고, 그 다음으로는 조경밀(33%)+금강밀(66%)가 우수한 결과를 보였다. 한편, 지역의 농가에서 수집한 밀 품종의 단백질 (유사도: 0.7231)\n",
      "[3] 밀 단백질 함량에 따라서 단백질이 낮은 조경밀(11～12%)에 단백질이 높은 금강밀(13～15%)을 블랜딩한 혼합밀가루의 식빵 품질 특성을 구명하였다. 한편, 국수용 블랜딩 혼합밀가루는다목적용도인 금강밀에 백중밀, 적중밀, 연백밀, 고소밀을 10～50%까지 대체 혼합하였을 때,밀가루 및 국수 가공 특성을 구명하였다. 국산 밀 3개 품종을 일정 비율로 블랜딩 (유사도: 0.7078)\n",
      "\n",
      "\n",
      "40/27983 14.초\n",
      "Question: 연구내용- In this stud\n",
      "[1] 신진연구 최종보고서양식A101① 부처사업명(대) 기초연구사업 보안등급(보안, 일반) 일반 Ⅰ. 연구계획 요약문② 사  업  명(중) 신진연구자지원사업 공개가능여부(공개, 비공개) 공개③ 세부사업명(소) 2014년 하반기 여성과학자지원사업 ④ 과제성격(기초, 응용, 개발) 기초  ④-1 실용화 대상여부(실용화, 비실용화) 비실용화   1. 국문요약문····· (유사도: 0.6610)\n",
      "[2] 〈  목   차  〉신진연구 최종보고서양식A101① 부처사업명(대) 기초연구사업 보안등급(보안, 일반) 일반 Ⅰ. 연구계획 요약문② 사  업  명(중) 신진연구자지원사업 공개가능여부(공개, 비공개) 공개③ 세부사업명(소) 2014년 하반기 여성과학자지원사업 ④ 과제성격(기초, 응용, 개발) 기초  ④-1 실용화 대상여부(실용화, 비실용화) 비실용화   1. (유사도: 0.6569)\n",
      "[3] 대표연구성과 요약문 [No 2] 대표연구성과 요약문 [No 3]Quantitative analysis of oral disease-causing bacteria in saliva among Consumption of Milk Prevents Dental Caries by Inhibiting Sugar 연구업적 제목 연구업적 제목bacterial cultur (유사도: 0.6521)\n",
      "\n",
      "\n",
      "45/27983 18.초\n",
      "Question: 1 세포주에 동물 및 사람 유래 NTM을 감염시켜 세포 내 CFU를 측정한 결\n",
      "[1]  동물 및 사람 유래 NTM과 BCG가 감염된 J774A.1 세포주에서의 CFU 측정 결과 (유사도: 0.9137)\n",
      "[2]      3) 수지상 세포의 T 세포 분화능 비교     ① T cell proliferation assay      - 전문 항원 제시세포로 알려진 수지상 세포에 의해서 체액성 면역에 관계되는 세포인 T 세포 그 중에서도 도움 CD4 T 세포와 독성 CD8 T 세포의 증식이 얼마나 이뤄지는 확인을 하고자 하는 실험을 진행하였다. 실험의 원리는 다음과 같다 (유사도: 0.8166)\n",
      "[3] 배양하였다. 이후 콜로니 카운팅을 통해서 CFU를 확인하였다.   □ 선별 균주 대상 면역 활성능 평가    ○ 수지상 세포의 maturation 비교     1) BCG와 후보균주에 감염된 수지상세포의 maturation marker (CD40, CD80, CD86, MHCII)의 확인       - 앞서 분리된 bone marrow derived cel (유사도: 0.8020)\n",
      "\n",
      "\n",
      "50/27983 28.초\n",
      "Question: _ _  2020년□ 특허 출원 건수6) Top 10 기관•  특허 출원 건수 Top 10 출원인을 살펴보\n",
      "[1] 2020년□ 특허 출원 건 수 6) Top 10 기 관•  특허 출원 건수 Top 10 출원인을 살펴보면, 일본 출원인 4개, 중국 출원인 3개, 한국 출원인 2개, 미국 출원인 1개로 구성되어 있음•  한국의 한국원자력연구원가 기건으로 가장 많은 특허를 출원하고 있으며, 복합재난 스마트 예측■대응기술 에서 한국원자력연구원는 전체 특허의 2 .2% 를 점유 (유사도: 0.7969)\n",
      "[2] _ _  2020년□ 특허 출원 건수6) Top 10 기관•  특허 출원 건수 Top 10 출원인을 살펴보면, 일본 출원인 6개 , 한국 출원인 2개 , 미국 출원인 2개로 구성되어 있음•  일본의 PANASONIC이 39건으로 가장 많은 특허를 출원하고 있으며, 범죄 ■테러 통합 지능형 예측■대응 시스템 기술에서 PANASONIC은 전체 특허의 3 .4  (유사도: 0.7832)\n",
      "[3] 2020년□ 특허 등록 건수7) T o p  10 기관•  특허 등록 건수 Top 10 출원인을 살펴보면, 한국 출원인 3개 , 중국 출원인 3개 , 일본 출원인 3개, 미국 출원인 1개로 구성되어 있음•  일본의 FUJITSU가 22건으로 가장 많은 등록특허를 보유하고 있으며, 재난 전주기 정보통신체계기술에서 FUJITSU는 전체 등록특허의 2.1 % 를 (유사도: 0.7751)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2088511/2000721550.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# Compute token embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mmodel_output2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoded_input2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/italian/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/italian/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m         )\n\u001b[1;32m   1008\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/italian/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/italian/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    590\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m                 )\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/italian/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/italian/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 514\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m         )\n\u001b[1;32m    516\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/italian/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2926\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2928\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/italian/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/italian/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/italian/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/italian/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/italian/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/italian/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!pip install -U sentence-transformers\n",
    "#from sentence_transformers import SentenceTransformers, util\n",
    "from sentence_transformers import util\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import json\n",
    "import time\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "def cosine(u, v):\n",
    "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('jhgan/ko-sbert-nli')\n",
    "model = AutoModel.from_pretrained('jhgan/ko-sbert-nli')\n",
    "#model = SentenceTransformer(\"Huffon/sentence-klue-roberta-base\")\n",
    "\n",
    "infile = 'q1.json'\n",
    "outfile = 'a1.json'\n",
    "\n",
    "with open(infile, encoding='UTF-8') as f:\n",
    "    #json_data = json.load(f)\n",
    "    json_data =json.loads(f.read())\n",
    "    #lines = f.readlines()\n",
    "\n",
    "    \n",
    "'''\n",
    "cont=\"\"\n",
    "for line in lines:\n",
    "    cont = cont+line;\n",
    "\n",
    "json_data = json.loads(cont)\n",
    "'''\n",
    "json_out = []\n",
    "cnt = 0\n",
    "for d in json_data:\n",
    "    cnt = cnt+1\n",
    "    start = time.time()\n",
    "    problem_no = d['problem_no']\n",
    "    task_no = d['task_no']\n",
    "    doc_file = d['doc_file']\n",
    "    question = d['question']\n",
    "    paras = d['paras']\n",
    "    sent = d['sent']\n",
    "    para = d['para']\n",
    "    pat = d['pat']\n",
    "    \n",
    "    \n",
    "    query = question\n",
    "    sentences = paras\n",
    "    ####sentences.append(question)\n",
    "    \n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "    encoded_input2 = tokenizer(query, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "        model_output2 = model(**encoded_input2)\n",
    "\n",
    "    # Perform pooling. In this case, mean pooling.\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    query_embedding = mean_pooling(model_output2, encoded_input2['attention_mask'])\n",
    "\n",
    "    #sentence_embeddings = model_output[:-1]\n",
    "    #query_embedding = model_output[-1]\n",
    "\n",
    "    top_k = min(3, len(sentences))\n",
    "    cos_scores = util.pytorch_cos_sim(query_embedding, sentence_embeddings)[0]\n",
    "    top_results = torch.topk(cos_scores, k=top_k)\n",
    "    \n",
    "    a = {}\n",
    "    a['team_id']=\"\"\n",
    "    a['hash']=\"\"\n",
    "    a['problem_no']=problem_no\n",
    "    a['task_no']=task_no\n",
    "    \n",
    "    a['doc_file']=doc_file\n",
    "    a['time']=delta\n",
    "    a['question'] = question\n",
    "    a['para'] = para\n",
    "    answer = []\n",
    "    for i, (score, idx) in enumerate(zip(top_results[0], top_results[1])):\n",
    "        rank = str(i+1);\n",
    "        paragraph = sentences[idx]\n",
    "        ans={}\n",
    "        ans['rank']=rank\n",
    "        ans['paragraph']=paragraph\n",
    "        answer.append(ans)\n",
    "    a['answer']=answer\n",
    "    a['sent'] = sent\n",
    "    delta = str(time.time()-start)\n",
    "    \n",
    "    \n",
    "    json_out.append(a);\n",
    "    #if(cnt%500==0):\n",
    "    if(cnt%5==0):\n",
    "        out = open(outfile,'w')\n",
    "        out.write(json.dumps(json_out, ensure_ascii=False, indent=4))\n",
    "        out.close();\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        print(str(cnt)+\"/\"+str(len(json_data))+\" \"+str(delta)[:4]+\"초\");\n",
    "        print(f\"Question: {query}\")\n",
    "        #print(f\"<입력 문장과 유사한 {top_k} 개의 문장>\")\n",
    "\n",
    "        for i, (score, idx) in enumerate(zip(top_results[0], top_results[1])):\n",
    "            print(f\"[{i+1}] {sentences[idx][0:min(200,len(sentences[idx]))]} {'(유사도: {:.4f})'.format(score)}\")\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d53746e-0df9-498a-af28-645320ac890f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "italian",
   "language": "python",
   "name": "italian"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
