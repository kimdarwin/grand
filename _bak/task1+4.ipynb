{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65de98a2-9872-420e-830d-d52dbca151c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로딩 중(~5초)\n",
      "\n",
      "\n",
      "2/27983 15.3초\n",
      "Question: 실험식이를 진행한 12주 동안 mouse body weight 변화 (n=6-9\n",
      "Pred_qa: mice / group\n",
      "[1] 실험식이를 진행한 12주 동안 mouse body weight 변화 (n=6-9 mice/group), *: HFD군과 비교하여 유의적인 차이 (*:p<0.05, **:p<0.01, ***:p<0.001, ****:p<0.0001) (유사도: 0.8470)\n",
      "\n",
      "\n",
      "4/27983 3.65초\n",
      "Question: (Arg1 상승이 유지됨)l\n",
      "Pred_qa: \n",
      "[1] l GNP-CD163를 처리해주었을 경우, 다른 성상의 macrophages 에 비해 TAM2 (M2 macrophages)에서 GNP uptake 가 증가한 것을 IF Staining으로 확인하였고, TEM에서도 확인함. (유사도: 0.4909)\n",
      "\n",
      "\n",
      "6/27983 14.2초\n",
      "Question: 또한 예주권역은 영해면의 중심부에 위치하여 영덕군청에서 북쪽으로 약 15km거리에 있으며 동쪽으로는\n",
      "Pred_qa: 동해바다\n",
      "[1] 영덕군 영해면 성내리, 괴시리, 연평리 일원(법정리 3개, 행정리 10개, 자연마을 12개) 면적825ha(농경지:340ha, 임야:316ha, 기타:169ha)으로 예주권역은 영해면의 중심부에 위치하여 영덕군청에서 북쪽으로 약 15km거리에 있으며 동쪽으로는 동해바다, 서쪽으로는 창수면, 남쪽으로는 축산면, 북쪽으로는 병곡면과 접해 있습니다. (유사도: 0.8002)\n",
      "\n",
      "\n",
      "8/27983 5.54초\n",
      "Question: 대상자의 자기관리 교육 요구도 항목별 중요도 순위는 1) 증상 및\n",
      "Pred_qa: 징후\n",
      "[1] 대상자의 자기관리 교육 요구도 항목별 중요도 순위는 1) 증상 및 징후, 2) 약물관련 정보, 3) 질병의 예후, 4) 위험요인, 5) 일반적 질병 정보, 6) 식이, 7) 신체활동, 8) 심리관련 정보 순이었다 (유사도: 0.8663)\n",
      "\n",
      "\n",
      "10/27983 13.7초\n",
      "Question: ‘Halla Gold’) 같은 골드키위들이 계속해서 육성 보급되는 계기가 되었다(Kim\n",
      "Pred_qa: Kim 등\n",
      "[1] ‘Halla Gold’) 같은 골드키위들이 계속해서 육성 보급되는 계기가 되었다(Kim 등,2007a; 김 등, 2009; 김 등, 2012; 국립종자원, 2016). (유사도: 0.9224)\n",
      "\n",
      "\n",
      "12/27983 2.89초\n",
      "Question: 결과: (1)\n",
      "Pred_qa: 9 -\n",
      "[1] - 9 - (유사도: 0.4019)\n",
      "\n",
      "\n",
      "14/27983 20.7초\n",
      "Question: \n",
      "Pred_qa: 3\n",
      "[1] 3 (유사도: 0.6623)\n",
      "\n",
      "\n",
      "16/27983 17.3초\n",
      "Question: 동시출현 네트워크의\n",
      "Pred_qa: 동시 출현 네트워크 [ 그림 18 ] 인용 네트워크\n",
      "[1] [그림 17] 동시 출현 네트워크 [그림 18] 인용 네트워크 (유사도: 0.7719)\n",
      "\n",
      "\n",
      "18/27983 22.9초\n",
      "Question: (2) 연구수행방법 (가) 실험동물 수컷 7주령의 C57bl/6Jj 생쥐 (웅성 8주령 24g 생쥐)는 대한바이오링크\n",
      "Pred_qa: eumseong, Korea )\n",
      "[1] (2) 연구수행방법 (가) 실험동물 수컷 7주령의 C57bl/6Jj 생쥐 (웅성 8주령 24g 생쥐)는 대한바이오링크 (eumseong, Korea)에서 공급받았고, 동물은 실험 당일까지 고형사료 (항생제 무첨가, 삼양사료 Co.)와 물을 충분히 공급하고, 온도 22±2℃, 습도 55±15%, 12 시간 light-dark cycle의 환경을 유지하며 1 주간 적응시킨 후 실험에 사용한다. (유사도: 0.8702)\n",
      "\n",
      "\n",
      "20/27983 8.33초\n",
      "Question: 뇌척수액 ELISPOT 검사를 다른 검사(뇌척수액 그람염색과 cryptococcal latex agglutination test)와 함께 사용할\n",
      "Pred_qa: 뇌척수액 그람염색과 cryptococcal latex agglutination test\n",
      "[1] 구분 5월 6월 7월 8월 9월 10월 11월 12월결핵성 뇌수막염 의심 환자의 혈액‧뇌척수액 검체 수집진단시 뇌척수액 및 말초혈액 ELISPOT 검사에 관한 연구치료 시작 후 말초 혈액 추적 ELISPOT 검사에 관한 연구ELISPOT 검사의 결과 판독을 점검ELISPOT 검사의 적절 cut-off value 결정ELISPOT 검사를 통한 진단 모델 개발 (유사도: 0.8430)\n",
      "\n",
      "\n",
      "22/27983 19.0초\n",
      "Question: 성능지표 측정결과(1) 열전도도∎ 아래의 사진두 개의 그래프는 기존공법과 개발공법 모형의 지중\n",
      "Pred_qa: \n",
      "[1] <기존공법모형의 지중 입∙출구온도 및 평균온도><개발공법모형의 지중 입∙출구온도 및 평균온도>∎ 위 두 그래프는 각각 기존공법, 개발공법의 입∙출구 및 평균온도를 나타낸 그래프- 33 - (유사도: 0.8080)\n",
      "\n",
      "\n",
      "24/27983 29.8초\n",
      "Question: 연구내용 및 범위연구범위는 한•미 수의사 면허와\n",
      "Pred_qa: 서비스\n",
      "[1] 연구내용 및 범위연구범위는 한•미 수의사 면허와 서비스, 수의사자격 상호인정, 수의학교 육과 인증, 공공 수의서비스에 관한 자료를 조사하는 것이다. (유사도: 0.8640)\n",
      "\n",
      "\n",
      "26/27983 31.0초\n",
      "Question: 우리 나라에는 고등교육인 의학\n",
      "Pred_qa: \n",
      "[1] 12 Envisioning the Future o f Veterinary Medical Education: The Association o f American Veterinary Medical Colleges Foresight Project, Final Report. (유사도: 0.6090)\n",
      "\n",
      "\n",
      "28/27983 4.45초\n",
      "Question: - quantitiatve RT-PCR을 통해서 microarray 분석 결과를 확인한 결과 가장 큰 폭으로 일관된 증가를 보이는 것은\n",
      "Pred_qa: ENSRNOT000000076904\n",
      "[1] - quantitiatve RT-PCR을 통해서 microarray 분석 결과를 확인한 결과 가장 큰 폭으로 일관된 증가를 보이는 것은 NR_027324, XR_600374, XR_349578, 그리고 가장 감소폭이 큰 것은 ENSRNOT000000076904로 확인됨.- (유사도: 0.9196)\n",
      "\n",
      "\n",
      "30/27983 17.5초\n",
      "Question: 빵부피는 국산밀 품종에 따라 비교적 큰 차이를\n",
      "Pred_qa: 금강밀\n",
      "[1] 빵부피는 국산밀 품종에 따라 비교적 큰 차이를 보였는데, 금강밀이 837 ㎤, 조경밀 775 ㎤, 조품밀이 700 ㎤ 수준이었고, 빵용 수입밀은 875～900 ㎤ 로 비교적 높았다. (유사도: 0.8631)\n",
      "\n",
      "\n",
      "32/27983 16.9초\n",
      "Question: 글루텐 특성인 WGC 함량은 36.0～37.0%(강력분\n",
      "Pred_qa: 11. 97 33. 5\n",
      "[1] 밀 블랜딩밀가루(%) 글루텐 특성(%)금강밀 연백밀 회분 단백질 SDSF GI WGC DGC WB100 0.56 12.52 38.0 93.3 28.0 9.3 18.7100 0.54 11.97 33.5 89.8 26.9 8.8 18.1- 20 - (유사도: 0.7211)\n",
      "\n",
      "\n",
      "34/27983 17.1초\n",
      "Question: 수입밀 HRW에 적중밀을 5～30% 블랜딩한 혼합밀가루의 단백질 함량은 10.77～11.65%\n",
      "Pred_qa: 11. 17 %, 적중밀 8. 57 %\n",
      "[1] 수입밀 HRW에 적중밀을 5～30% 블랜딩한 혼합밀가루의 단백질 함량은 10.77～11.65% 수준으로서, HRW 11.17%, 적중밀 8.57%, 시판 중력분 11.0%와 비교할 때 유사한 경향을 보인다. (유사도: 0.9111)\n",
      "\n",
      "\n",
      "36/27983 13.2초\n",
      "Question: 음성통화 기능 설문조사 결과를 토대로 제외 0%기타성과기존 인프라와 단말을 활용함으로써 초기 투자비용\n",
      "Pred_qa: \n",
      "[1] 도입 후 : SmartBell 만을 단독적으로 이용함으로써 위의기술된 효과 이외에 부수적으로 필요로 하는 설치 비용을획기적으로 감소시킴. (유사도: 0.6071)\n",
      "\n",
      "\n",
      "38/27983 13.0초\n",
      "Question: 현재 가장 큰 시장을 형성하고 있는 미국의\n",
      "Pred_qa: 분야별 보급률바\n",
      "[1] 미국의 분야별 보급률바. (유사도: 0.4830)\n",
      "\n",
      "\n",
      "40/27983 17.1초\n",
      "Question: 연구내용- In this\n",
      "Pred_qa: study\n",
      "[1] 대표연구성과 요약문 [No 2] 대표연구성과 요약문 [No 3]Quantitative analysis of oral disease-causing bacteria in saliva among Consumption of Milk Prevents Dental Caries by Inhibiting Sugar 연구업적 제목 연구업적 제목bacterial culture, SYBRgreen qPCR and MRT-PCR method Fermentation   학술지게재논문(■)   저서( )   역서( )   특허( )   국제학회 초청강연( )      학술지게재논문(■)   저서( )   역서( )   특허( )   국제학회 초청강연( )   연구업적 유형 연구업적 유형   학술지 편집위원 참여( )   기술이전( )    학술지 편집위원 참여( )   기술이전( )게재연도  2017년 4월 게재연도  2017년 3월주관연구책임자 또는 주관연구책임자 또는 박용덕, 오혜영, 박복리, 조아라,  (유사도: 0.6507)\n",
      "\n",
      "\n",
      "42/27983 4.01초\n",
      "Question: 3400 wavenumber\n",
      "Pred_qa: 3400 wavenumber\n",
      "[1] 202007.- (유사도: 0.4714)\n",
      "\n",
      "\n",
      "44/27983 18.6초\n",
      "Question: 1 세포주에 동물 및 사람 유래 NTM을 감염시켜 세포 내 CFU를 측정한\n",
      "Pred_qa: 1\n",
      "[1] 1 세포주에서의 CFU 측정 결과 (유사도: 0.7917)\n",
      "\n",
      "\n",
      "46/27983 13.0초\n",
      "Question: 축산물마케팅채널에 관한 연구로는 한우시장의 구조와 가격분석에 관한\n",
      "Pred_qa: 연구\n",
      "[1] 축산물마케팅채널에 관한 연구로는 한우시장의 구조와 가격분석에 관한 연구(이해종, 1975a; 이해종, 1975b; 이해종, 1975c; 이해종, 1976), 식육유통구조의 실태 및 개선방향에 관한 연구(하서현 외, 1990) 등이 있다. (유사도: 0.8737)\n",
      "\n",
      "\n",
      "48/27983 28.0초\n",
      "Question: 2020년□ 특허 출원 건 수 6) Top 10 기 관•  특허 출원 건수 Top 10 출원인을\n",
      "Pred_qa: 2\n",
      "[1] 2020년□ 특허 출원 건 수 6) Top 10 기 관•  특허 출원 건수 Top 10 출원인을 살펴보면, 일본 출원인 4개, 중국 출원인 3개, 한국 출원인 2개, 미국 출원인 1개로 구성되어 있음•  한국의 한국원자력연구원가 기건으로 가장 많은 특허를 출원하고 있으며, 복합재난 스마트 예측■대응기술 에서 한국원자력연구원는 전체 특허의 2 . (유사도: 0.8443)\n",
      "\n",
      "\n",
      "50/27983 28.0초\n",
      "Question: _ _  2020년□ 특허 출원 건수6) Top 10 기관•  특허 출원 건수 Top 10 출원인을\n",
      "Pred_qa: 2\n",
      "[1] 2020년□ 특허 출원 건 수 6) Top 10 기 관•  특허 출원 건수 Top 10 출원인을 살펴보면, 일본 출원인 4개, 중국 출원인 3개, 한국 출원인 2개, 미국 출원인 1개로 구성되어 있음•  한국의 한국원자력연구원가 기건으로 가장 많은 특허를 출원하고 있으며, 복합재난 스마트 예측■대응기술 에서 한국원자력연구원는 전체 특허의 2 . (유사도: 0.8248)\n",
      "\n",
      "\n",
      "52/27983 28.0초\n",
      "Question: 2020년□ 특허 출원 건수6) T o p  10 기관•  특허 출원 건수 Top 10 출원인을\n",
      "Pred_qa: 2\n",
      "[1] 2020년□ 특허 출원 건 수 6) Top 10 기 관•  특허 출원 건수 Top 10 출원인을 살펴보면, 일본 출원인 4개, 중국 출원인 3개, 한국 출원인 2개, 미국 출원인 1개로 구성되어 있음•  한국의 한국원자력연구원가 기건으로 가장 많은 특허를 출원하고 있으며, 복합재난 스마트 예측■대응기술 에서 한국원자력연구원는 전체 특허의 2 . (유사도: 0.8272)\n",
      "\n",
      "\n",
      "54/27983 28.3초\n",
      "Question: 재난현장 소방구조 장비•시스템 기술□ 논문 등재 건수 T이D 10 기관•  논문 등재 건수 Top 10 기관을\n",
      "Pred_qa: \n",
      "[1] 재난현장 소방구조 장비•시스템 기술□ 논문 등재 건수 T이D 10 기관•  논문 등재 건수 Top 10 기관을 살펴보면, 중국 기관 5개 , 미국 기관 4개 , 일본 기관 1개로 구성되어 있음•  중국의 STATE KEY LABORATORY OF FIRE SCIENCE가 42건으로 가장 많은 논문을 발행했으며, 재난현장 소방구조 장비 ■시스템 기술에서 STATE KEY LABORATORY OF FIRE SCIENCE는 전체 논문의 4 . (유사도: 0.8197)\n",
      "\n",
      "\n",
      "56/27983 28.0초\n",
      "Question: 2020년□ 특허 등록 건수7) Top 10 기관•  특허 등록 건수 Top 10 출원인을\n",
      "Pred_qa: 2\n",
      "[1] 2020년□ 특허 출원 건 수 6) Top 10 기 관•  특허 출원 건수 Top 10 출원인을 살펴보면, 일본 출원인 4개, 중국 출원인 3개, 한국 출원인 2개, 미국 출원인 1개로 구성되어 있음•  한국의 한국원자력연구원가 기건으로 가장 많은 특허를 출원하고 있으며, 복합재난 스마트 예측■대응기술 에서 한국원자력연구원는 전체 특허의 2 . (유사도: 0.8216)\n",
      "\n",
      "\n",
      "58/27983 8.28초\n",
      "Question: 실제 효모 조추출물에 이 항체를 ELISA (그림\n",
      "Pred_qa: ELISA\n",
      "[1] 효모 성장에 따른 cTPx II 단백질 발현 양상. (유사도: 0.7182)\n",
      "\n",
      "\n",
      "60/27983 22.9초\n",
      "Question: 관제 시스템 개발 - 기사(차주)용 앱을 개발하여 한번이라도 배차를 받은 실적이 있는 차량 회원이   라면 앱 이용이 가능하도록\n",
      "Pred_qa: 개발하였으며, 배차 내역 보기, 화물 상세 보기, 상담원 연결 기능이 구현되도록 개발하였음\n",
      "[1] 관제 시스템 개발 - 기사(차주)용 앱을 개발하여 한번이라도 배차를 받은 실적이 있는 차량 회원이   라면 앱 이용이 가능하도록 개발하였으며, 배차 내역 보기, 화물 상세 보기,   상담원 연결 기능이 구현되도록 개발하였음.- (유사도: 0.9662)\n",
      "\n",
      "\n",
      "62/27983 4.08초\n",
      "Question: 기존의 표준 치료인 3주 간격의 CHOP\n",
      "Pred_qa: \n",
      "[1] Dose-dense  paclitaxel  once  a  week  in  combination  with  carboplatin  every  3  weeks  for  advanced  ovarian  cancer: a  phase  3, open-label, randomised  controlled  trial. (유사도: 0.6522)\n",
      "\n",
      "\n",
      "64/27983 10.3초\n",
      "Question: 흉선 T세포 발생과정을 분석하기 위하여\n",
      "Pred_qa: FACS 기기를 이용하여 분석하였다\n",
      "[1] 흉선 T세포 발생과정을 분석하기 위하여 Twist2-Tg, OT2-TCR-Tg, Rip-mOVA-Tg, Twist2-KO 마우스 등의 흉선 면역세포 표현형을 FACS 기기를 이용하여 분석하였다. (유사도: 0.8735)\n",
      "\n",
      "\n",
      "66/27983 7.28초\n",
      "Question: \n",
      "Pred_qa: 5\n",
      "[1] 5. (유사도: 0.5638)\n",
      "\n",
      "\n",
      "68/27983 7.37초\n",
      "Question: 29~63(35pages) 양성욱 •\n",
      "Pred_qa: 63\n",
      "[1] 30 2차년도 15,200,000원 1명(2년)계 30,400,000원 3명- 1 - (유사도: 0.6334)\n",
      "\n",
      "\n",
      "70/27983 29.0초\n",
      "Question: 70°C·GIS/DB시스템      - DGPS 신호와 연동된 전 계측시스템의 취득데이터를 바탕으로\n",
      "Pred_qa: \n",
      "[1] 70°C·GIS/DB시스템      - DGPS 신호와 연동된 전 계측시스템의 취득데이터를 바탕으로 점, 선, 면과 인문학적 지형정보를 대용량 데이터베이스와 연동하여 관리 및 분석      - GIS Interface(Basic Gis Tools-Add date, Zoom in/out, Identify, Pan, and etc.)      - (유사도: 0.8656)\n",
      "\n",
      "\n",
      "72/27983 29.7초\n",
      "Question: (6)6) RI 값은 항목 수 이 3일 때\n",
      "Pred_qa: 6 ) RI 값은 항목 수 이 3일 때\n",
      "[1] 3-3계층 중요도 산출 결과 (유사도: 0.7552)\n",
      "\n",
      "\n",
      "74/27983 8.79초\n",
      "Question: 한국보건사회연구원15) Mathers\n",
      "Pred_qa: \n",
      "[1] 학술대회 논문발표 성과정보과제번호 발표년월 학술대회명 저자 논문제목 학술대회구분 개최국Sarcopenia and Leukocyte Telomere Length in US 2017R1D1A1B 제69차 대한예방의학회 추계학 김정훈, 곽정현, Adults: The National 201710 국내학술대회 대한민국03035192 술대회 최윤형 Health and Nutrition Examination Survey 1999-2002Associations of Sarcopenia with 2017R1D1A1B 제69차 대한예방의학회 추계학 윤정교, 김정훈, Rheumatoid Arthritis and 201710 국내학술대회 대한민국03035192 술대회 최윤형 Osteoarthritis in Middle-aged and Older KoreanType of Physical Activity 2017R1D1A1B 제69차 대한예방의학회 추계학 and Medical Expenditure 20171 (유사도: 0.6578)\n",
      "\n",
      "\n",
      "76/27983 26.6초\n",
      "Question: 본 과제와 관련하여 정상대조군으로 총 45명 (2011년\n",
      "Pred_qa: 2011\n",
      "[1] [특허성과]1 특허명등록인 국/내외 구분(국가) 국내/국외(국가명)등록번호 등록년월일 2010-05-01본 연구과제와의 관련성*관련 마일스톤... (유사도: 0.4859)\n",
      "\n",
      "\n",
      "78/27983 16.2초\n",
      "Question: 요드드화물은 lithium\n",
      "Pred_qa: iodide\n",
      "[1] 요드드화물은 lithium iodide, magnesium iodide, aluminum iodide, titanium iodide, tin iodide을 500 ppm, 1000 ppm, 3000 ppm, 5000 ppm의 농도로 첨가함.- (유사도: 0.7063)\n",
      "\n",
      "\n",
      "80/27983 15.7초\n",
      "Question: - 본 연구에서는 리튬-황전지의 전해질로써 요오드화물 염을 포함하는 전해질을\n",
      "Pred_qa: 요오드화물 염\n",
      "[1] 본 연구에서는, donor number가 높은 용매를 전해질로 사용할 수밖에 없는 리튬-황전지 시스템에서, 용해성 폴리설파이드 셔틀반응을 제어하는 연구를 시도함으로써 리튬-황전지의 전기화학적 성능을 높임.○ (유사도: 0.8623)\n",
      "\n",
      "\n",
      "82/27983 21.5초\n",
      "Question: 이를 해결하기 위해 본 연구에서는 죄 상세 유형(참작 동기\n",
      "Pred_qa: 보통동기 ( 죄 상세 유형 )\n",
      "[1] <표 18> 보통동기(죄 상세 유형)-살인미수(죄명)의 사건들에 대해 법·사회적 요인을 고려했을 (유사도: 0.7023)\n",
      "\n",
      "\n",
      "84/27983 21.2초\n",
      "Question: 하지만 형량이 매우 큰 죄 상세 유형들(극단적 인명 경시(살인\n",
      "Pred_qa: \n",
      "[1] 하지만 형량이 매우 큰 죄 상세 유형들(극단적 인명 경시(살인 1건, 강도 살인 9건, 성폭력 범죄 1건, 강간살인 2건, 강도 살인 미수 9건), 중대범죄결합(살인 2건, 성폭렴 범죄 1건, 살인미수 2건) 등)의 경우는 시스템에 충분히 학습되지 않은 상태이며, 이는 추후 연구에서 데이터 확장을 통해 시스템 개발을 진행해야할 필요가 있다. (유사도: 0.8353)\n",
      "\n",
      "\n",
      "86/27983 8.68초\n",
      "Question: 이 원격 의료 시스템에서는 환자의 상태 정보를 습득할 수 있는 체온 측정\n",
      "Pred_qa: 체온 측정 센서\n",
      "[1] 이 원격 의료 시스템에서는 환자의 상태 정보를 습득할 수 있는 체온 측정 센서, 혈압 측정 센서, 심박 측정 센서, 혈액 성분 분석 센서 등 다양한 측정 센서들로부터 제공되는 센서 정보들과 6DoF 비디오 신호를 결합하여 원격 진료 및 의료 시스템을 구축함. (유사도: 0.8318)\n",
      "\n",
      "\n",
      "88/27983 27.4초\n",
      "Question: 자원소비셰일가스 생산과 관련하여 토지를\n",
      "Pred_qa: 소모되는 물질의 양\n",
      "[1] 천연가스 개발과 관련된 활동에서 소모되는 물질의 양 (유사도: 0.7901)\n",
      "\n",
      "\n",
      "90/27983 10.4초\n",
      "Question: 암의 잦은 발병으로 인하여 사회경제적 부담이 가중되고 있는데 (2002년\n",
      "Pred_qa: 2002년 기준\n",
      "[1] 암의 잦은 발병으로 인하여 사회경제적 부담이 가중되고 있는데 (2002년 기준, 11조 3천억 원), 실제로 위암과 간암: 각각 2조 이상, 폐암: 1조 5천억, 대장암: 9천 7백억, 유방암: 5천8백억, 자궁경부암: 3천 3백억 등을 부담하고 있음.○ (유사도: 0.9032)\n",
      "\n",
      "\n",
      "92/27983 21.2초\n",
      "Question: [1]\n",
      "Pred_qa: 27 -\n",
      "[1] - 27 - (유사도: 0.5357)\n",
      "\n",
      "\n",
      "94/27983 16.7초\n",
      "Question: 현a卜 2>*1\n",
      "Pred_qa: ( A [UNK] • ‘ ， 서 K / | 1 ( ). \n",
      "[1] 1니 ，-( A 乂 •‘， 서 K /|1( ). (유사도: 0.7392)\n",
      "\n",
      "\n",
      "96/27983 14.8초\n",
      "Question: 옹진\n",
      "Pred_qa: 옹진\n",
      "[1] 18 (유사도: 0.4461)\n",
      "\n",
      "\n",
      "98/27983 22.1초\n",
      "Question: 호주의 Hoolywood fish farm1)\n",
      "Pred_qa: Hoolywood fish farm1 )\n",
      "[1] 호주 AQ1 systmes : SF200 Feeding system for Shrimp나. (유사도: 0.5725)\n",
      "\n",
      "\n",
      "100/27983 27.0초\n",
      "Question: 분석 대상이 되는 회수물/폐기물은 회수우라늄\n",
      "Pred_qa: 회수 TRU 금속\n",
      "[1] 분석 대상이 되는 회수물/폐기물은 회수우라늄 금속, 회수 TRU 금속, LiCl 염폐기물, LiCl-KCl 공융염 폐기물, NM 폐기물, 희토류 폐기물 등임.○ (유사도: 0.8974)\n",
      "\n",
      "\n",
      "102/27983 5.58초\n",
      "Question: 약물관련 악골괴사 관련 실험 논문 및 임상 논문들을 검색하여 약물관련 악골괴사가 일어나는 조건에서의 cytokine의\n",
      "Pred_qa: 상태\n",
      "[1] 약물관련 악골괴사 관련 실험 논문 및 임상 논문들을 검색하여 약물관련 악골괴사가 일어나는 조건에서의 cytokine의 상태, 치료 후의 cytokine의 상태, Osteoblast, Osteoclast, Osteocyte, Osteomac의 활성화 상태, RANKL, RANK, OPG 등 bone remodeling과 관련연구내용 된 실험 논문들의 자료를 수집하고 본 modeling에 이용할 수 있는 자료들을 분석한다. (유사도: 0.9020)\n",
      "\n",
      "\n",
      "104/27983 12.8초\n",
      "Question: 사고원인 중 자연 재해만의 기준으로 볼 때 평지의 경우 홍수에 의한 재해는 없었으나\n",
      "Pred_qa: 3.\n",
      "[1] 건설공사에 대한 자연재해임을 고려하여 황사, 가뭄 제외 3. (유사도: 0.6244)\n",
      "\n",
      "\n",
      "106/27983 13.8초\n",
      "Question: 추가적인 R&D 수행 이후 연구 개발된 소자를 통해 해당 기술을 ㈜ TSE로 MEMS 릴레이 신뢰성 향상 기술 이전 (협의 중)반도체\n",
      "Pred_qa: \n",
      "[1] 2차년도에는 본 연구실에서 1 차년도에 개발된 고 신뢰성을 가지는 MEMS 릴레이 기술을㈜ TSE로 이전하고, MEMS 릴레이의 실제 양산화에 적합한 상용 소자의 동작 수율, 스트레스에 따른 휨 안정성 및 고온에서의 구조적 안정성을 ㈜ TSE 기업과의기술 교류회를 통해 개선하고자 하였다. (유사도: 0.8627)\n",
      "\n",
      "\n",
      "108/27983 22.1초\n",
      "Question: 이 자4  전년도 이월금합 계 5\n",
      "Pred_qa: 5 1\n",
      "[1] 이 자4  전년도 이월금합 계 5 1 ,6 6 7 1 5 ,0 0 3 5 1 ,6 6 7 1 5 JX & 0 0著 1. (유사도: 0.8207)\n",
      "\n",
      "\n",
      "110/27983 30.6초\n",
      "Question: 그동안 원자력사업자 및 유관기관 전문가들로부터 257건의 검토의견을\n",
      "Pred_qa: IPPAS 자문보고서 검토\n",
      "[1] 첫 번째로 IPPAS 자문보고서 검토는 2014년 3월 7일 IPPAS가 종료된 이후 각 기관이 해당 내용을 검토할 시간을 갖고, 3월 25일까지 수검기관 별 수정의견을 취합하고 내용을 협의하였다. (유사도: 0.5542)\n",
      "\n",
      "\n",
      "112/27983 12.7초\n",
      "Question: 분자비컨 제작을 위한 miRNA 후보로서\n",
      "Pred_qa: n 대장암 유발 miRNA\n",
      "[1] n 대장암 유발 miRNA에 대한 miRNA-MB 제작Ÿ 분자비컨 후보 miRNA 중 가장 적합한 것으로 선택된 miR-141-3p의 상보적인 염기 서열에 Cy3.0을 붙이고 (reporter oligo), 이 reporter oligo가 miR-141-3p와 결합할 경우에만 signal-on이 되게 하기 위하여, 평상시에는 Cy3.0의 형광 에너지를 흡수하여 signal-off 상태를 유지시켜주는 quencher (BHQ1)가 부착된 quencher oligo를 reporter oligo에 결합한 분자 비컨 (miR-141 MB)를 제작함. (유사도: 0.7687)\n",
      "\n",
      "\n",
      "114/27983 19.2초\n",
      "Question: 옥수수 시료는 500 ㎍/mL에 서 61.8± 0.9% 의 ABTS free radical 소거능을 보였고\n",
      "Pred_qa: 26. [UNK]. 2 %\n",
      "[1] 옥수수 시료는 500 ㎍/mL에 서 61.8± 0.9% 의 ABTS free radical 소거능을 보였고 수수, 검은콩, 흑미, 메밀은 100 ㎍/mL에서 각 각 18.6±0.9 % , 29.8± 0.9 %, 26.6±1.2 %, 37.2± 7.1 % 의 ABTS free radical 소거능을 보였다. (유사도: 0.9101)\n",
      "\n",
      "\n",
      "116/27983 24.5초\n",
      "Question: 산업용PDA 제품의 기본적인 강점인 내구성(IP54 방수∙방진 /1.2m 낙하)과 다양한      데이터 인식 기능 (1D 레이저\n",
      "Pred_qa: 바코드 스캐너\n",
      "[1] o 산업용PDA 특징 이미지 주요 스펙 OS Windows CE, Windows Mobile, Android무선통신 HSPA+, LTE, 무선랜 802.11 a/b/g/n, 블루투스 견고성 IP54~67(방수, 방진), 낙하테스트1D 레이저 바코드 스캐너, 2D 이미지 바코드 데이터캡처 스캐너, HF RFID 리더, IC 카드 판독기, 카메라 5.0M pixel, A-GPS, MSR, MRZ리더 스냅온CPU Arm core 기반 프로세서 : 퀄컴, 삼성MSR, MRZ리더 스냅온, 데스크톱 크래들액세서리 (Ethernet, USB), 차량용 충전기, 차량용 거치대, Serial 통신 케이블 등 (유사도: 0.7529)\n",
      "\n",
      "\n",
      "118/27983 26.2초\n",
      "Question: . 연구개발의 내용 및 방법    탄소나노튜브 액정 섬유의 연속\n",
      "Pred_qa: \n",
      "[1] 4U (초고강도, 초고전기전도도, 초고열전도도, 초경량)를 달성하기 위한 액정섬유의 연구는  1)　액정 dope의 원재료인 탄소나노튜브의 합성 연구 (길이 및 결정성 연구), 2）생산된 탄소나노튜브의 화학적, 물리적 물성 제어연구 (길이 및 도핑 연구), 3）초강산 용매외 순수 탄소나노튜브의 액정상 발현 가능 용매 연구, ４）레올로지 및 시뮬레이션 기반 방사 최적화 연구, ５）생산된 액정섬유의 후처리 공정 연구 등 원재료부터 후처리까지 전주기적인 기술에 대한 연구가 필수적임.○ (유사도: 0.8624)\n",
      "\n",
      "\n",
      "120/27983 27.6초\n",
      "Question: 합성한 cDNA와 SYBRGreen Supermix와 특이 프라이머 쌍을혼합한 후 CFX96 RT-PCR System\n",
      "Pred_qa: Bio - rad, USA\n",
      "[1] 합성한 cDNA와 SYBRGreen Supermix와 특이프라이머 쌍을 혼합한 후 CFX96 RT-PCR System (Bio-rad, USA)을 이용하여 95°C에서 3분을반응시킨 후, 95°C에서 20초, 61°C에서 15초, 72°C에서 20초간 40회 반복하고, 매회 신장 단계에서SYBR/FAM channel로 형광량을 측정하였다. (유사도: 0.8682)\n",
      "\n",
      "\n",
      "122/27983 24.4초\n",
      "Question: 차세대 SSD가 제공하는 고속의 데이터 I/O는\n",
      "Pred_qa: Online Transaction Processing\n",
      "[1] ◦ ONFI 2.0 기반의 컨트롤러를 이용한 고속의 SSD는 ERP(Enterprise ResourcePlanning), OLTP(Online Transaction Processing), 전자메일 시스템, 멀티미디어스트리밍, 전자상거래 시스템 등 기업용 응용 시스템에 활용 가능하며, 이러한 시스템에 적용할 경우 I/O 속도의 획기적인 개선, 데이터 전송율 향상 및 빠른 응답속도가 보장되므로 시스템 효율을 극대화 할 수 있음.◦ (유사도: 0.7958)\n",
      "\n",
      "\n",
      "124/27983 24.0초\n",
      "Question: 다양한 변화를 수용할 수 있는 FTL의 개발 : 차세대 NAND 규격을 만족하기위해서는 다양한 페이지\n",
      "Pred_qa: 다양한 페이지 크기\n",
      "[1] 다양한 변화를 수용할 수 있는 FTL의 개발 : 차세대 NAND 규격을 만족하기위해서는 다양한 페이지 크기, 어드레스 사이클, 부분 프로그램 제한, 다양한 프로그램 지연시간, 읽기 지연시간 등을 수용할 수 있어야 한다. (유사도: 0.9359)\n",
      "\n",
      "\n",
      "126/27983 4.26초\n",
      "Question: 또한 복호 후 전송을 사용하는 전이중 중계 시스템에서 중계기의 전력 제어 기법은 통신 중계 역할을 하는\n",
      "Pred_qa: 자기 간섭 채널 ( self - interference channel )\n",
      "[1] 여기서 중계기는 전이중으로 동작하기 때문에 자기 간섭 채널(self-interference channel)이 존재하고 복호 후 전송을 사용한다. (유사도: 0.8613)\n",
      "\n",
      "\n",
      "128/27983 17.5초\n",
      "Question: 여기에는 이물(Foreign\n",
      "Pred_qa: P +\n",
      "[1] (1) 직경 2um의 이물(P+라 명명함)을 검출하는 화면(2) 직경 2um의 박리(P-라 명명함)를 검출하는 화면- 41 - (유사도: 0.5686)\n",
      "\n",
      "\n",
      "130/27983 11.3초\n",
      "Question: 1차 세그먼트 그룹에서 표로 추정되는 그룹에 대하여 표의 구성 형태가 정당한가를\n",
      "Pred_qa: \n",
      "[1] 1차 세그먼트 그룹에서 표로 추정되는 그룹에 대하여 표의 구성 형태가 정당한가를 점검하고, 표를 구성하는 셀, 셀 내부의 문단, 셀의 구분자(셀 외곽선 상태)등의 정보를 도출하였다 (유사도: 0.8831)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2120736/1118405135.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewsents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     \u001b[0msentence_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0mtop_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0mcos_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch_cos_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2120736/1118405135.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(sentences)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# Tokenize sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mencoded_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0;31m#encoded_input2 = tokenizer(query, padding=True, truncation=True, return_tensors='pt')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/italian/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2470\u001b[0m                 \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2473\u001b[0m             )\n\u001b[1;32m   2474\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/italian/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2661\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2662\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2663\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2664\u001b[0m         )\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/italian/lib/python3.7/site-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;31m# we add an overflow_to_sample_mapping array (see below)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0msanitized_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens_and_encodings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m             \u001b[0mstack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens_and_encodings\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0msanitized_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import json\n",
    "import time\n",
    "from kiwipiepy import Kiwi\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "def cosine(u, v):\n",
    "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
    "def replacecomma(m):        # 매개변수로 매치 객체를 받음\n",
    "    n = m.group().replace(\",\",\"\")    # 매칭된 문자열\n",
    "    return str(n)\n",
    "\n",
    "print(\"로딩 중(~5초)\")\n",
    "kiwi = Kiwi()\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('jhgan/ko-sbert-nli')\n",
    "model = AutoModel.from_pretrained('jhgan/ko-sbert-nli')\n",
    "#model = SentenceTransformer(\"Huffon/sentence-klue-roberta-base\")\n",
    "\n",
    "HUGGINGFACE_MODEL_PATH = \"bespin-global/klue-bert-base-mrc\"\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(HUGGINGFACE_MODEL_PATH )\n",
    "model2 = AutoModelForQuestionAnswering.from_pretrained(HUGGINGFACE_MODEL_PATH )\n",
    "\n",
    "#입출력 파일\n",
    "infile = 'q1.json'\n",
    "outfile = 'a1.json'\n",
    "outfile4 = 'a4.json'\n",
    "def bespin(context, question):\n",
    "    # Encoding\n",
    "    encodings = tokenizer2(context, question, \n",
    "                          max_length=512, \n",
    "                          truncation=True,\n",
    "                          padding=\"max_length\", \n",
    "                          return_token_type_ids=False\n",
    "                          )\n",
    "    encodings = {key: torch.tensor([val]) for key, val in encodings.items()}             \n",
    "    input_ids = encodings[\"input_ids\"]\n",
    "    attention_mask = encodings[\"attention_mask\"]\n",
    "\n",
    "    # Predict\n",
    "    pred = model2(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    start_logits, end_logits = pred.start_logits, pred.end_logits\n",
    "    token_start_index, token_end_index = start_logits.argmax(dim=-1), end_logits.argmax(dim=-1)\n",
    "    pred_ids = input_ids[0][token_start_index: token_end_index + 1]\n",
    "\n",
    "    # Decoding\n",
    "    prediction = tokenizer2.decode(pred_ids)\n",
    "    if(prediction.find('[SEP]')>0):\n",
    "        prediction = prediction[0:prediction.find('[SEP]')]\n",
    "    return prediction\n",
    "\n",
    "def encode(sentences):\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "    #encoded_input2 = tokenizer(query, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "        #model_output2 = model(**encoded_input2)\n",
    "\n",
    "    # Perform pooling. In this case, mean pooling.\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    #query_embedding = mean_pooling(model_output2, encoded_input2['attention_mask'])\n",
    "    return sentence_embeddings;\n",
    "\n",
    "\n",
    "\n",
    "with open(infile, encoding='UTF-8') as f:\n",
    "    #json_data = json.load(f)\n",
    "    json_data =json.loads(f.read())\n",
    "    #lines = f.readlines()\n",
    "\n",
    "    \n",
    "'''\n",
    "cont=\"\"\n",
    "for line in lines:\n",
    "    cont = cont+line;\n",
    "\n",
    "json_data = json.loads(cont)\n",
    "'''\n",
    "json_out = []\n",
    "json_out4 = []\n",
    "cnt = 0\n",
    "for d in json_data:\n",
    "    cnt = cnt+1\n",
    "    start = time.time()\n",
    "    problem_no = d['problem_no']\n",
    "    task_no = d['task_no']\n",
    "    doc_file = d['doc_file']\n",
    "    question = d['question']\n",
    "    paras = d['paras']\n",
    "    sent = d['sent']\n",
    "    para = d['para']\n",
    "    pat = d['pat']\n",
    "    #question 틀린점 있어서 마지막 한단어 제거함\n",
    "    tok = question.split(\" \")\n",
    "    question = \" \".join(tok[:-1])\n",
    "    \n",
    "    query = question\n",
    "    sentences = paras\n",
    "    ####sentences.append(question)\n",
    "    '''\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "    encoded_input2 = tokenizer(query, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "        model_output2 = model(**encoded_input2)\n",
    "\n",
    "    # Perform pooling. In this case, mean pooling.\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    query_embedding = mean_pooling(model_output2, encoded_input2['attention_mask'])\n",
    "    '''\n",
    "    sentence_embeddings = encode(sentences);\n",
    "    query_embedding = encode(query);\n",
    "    #sentence_embeddings = model_output[:-1]\n",
    "    #query_embedding = model_output[-1]\n",
    "\n",
    "    top_k = min(3, len(sentences))\n",
    "    cos_scores = util.pytorch_cos_sim(query_embedding, sentence_embeddings)[0]\n",
    "    top_results = torch.topk(cos_scores, k=top_k)\n",
    "    \n",
    "    a = {}\n",
    "    a['team_id']=\"\"\n",
    "    a['hash']=\"\"\n",
    "    a['problem_no']=problem_no\n",
    "    a['task_no']=task_no\n",
    "    \n",
    "    a['doc_file']=doc_file\n",
    "    a['question'] = question\n",
    "    a['answer_right'] = 0\n",
    "    a['para'] = para\n",
    "    answer = []\n",
    "    for i, (score, idx) in enumerate(zip(top_results[0], top_results[1])):\n",
    "        rank = str(i+1);\n",
    "        paragraph = sentences[idx]\n",
    "        if(para==paragraph):\n",
    "            a['answer_right']=i+1\n",
    "        \n",
    "        ans={}\n",
    "        ans['rank']=rank\n",
    "        ans['paragraph']=paragraph\n",
    "        answer.append(ans)\n",
    "    a['answer']=answer\n",
    "    a['sent'] = sent\n",
    "    delta = str(time.time()-start)\n",
    "    a['time']=delta\n",
    "    \n",
    "    #검색 응답 출력\n",
    "    json_out.append(a);\n",
    "    \n",
    "    #찾은 문단에서 QA 시작\n",
    "    pred_para = answer[0]['paragraph'];\n",
    "    sentences = kiwi.split_into_sents(pred_para)\n",
    "    newsents = []\n",
    "    for s in sentences:\n",
    "        newsents.append(s.text);\n",
    "    sentences = newsents\n",
    "    \n",
    "    if(sentences==[]):\n",
    "        continue;\n",
    "    if(len(sentences[0])==0):\n",
    "        continue;\n",
    "    \n",
    "    sentence_embeddings = encode(sentences);\n",
    "    top_k = min(1, len(sentences))\n",
    "    cos_scores = util.pytorch_cos_sim(query_embedding, sentence_embeddings)[0]\n",
    "    top_results = torch.topk(cos_scores, k=top_k)\n",
    "    \n",
    "    top1sent = \"\"\n",
    "    for i, (score, idx) in enumerate(zip(top_results[0], top_results[1])):\n",
    "        rank = str(i+1);\n",
    "        top1sent = sentences[idx]\n",
    "    \n",
    "    pred_qa = bespin(top1sent,question);\n",
    "    \n",
    "    #deepcopy보다 빠른 json 복사\n",
    "    #data_copy = json.loads(json.dumps(data))\n",
    "    a = json.loads(json.dumps(a))\n",
    "    \n",
    "    a['answer'] = pred_qa\n",
    "    a['task_no'] = \"4\"\n",
    "    evidence = []\n",
    "    e1 = {}\n",
    "    e1['doc']=doc_file\n",
    "    e2 = {}\n",
    "    e2['자료 유형(paragraph)']=pred_para\n",
    "    e3 = {}\n",
    "    e3['자료 유형(table/figure)']=\"\"\n",
    "    evidence.append(e1)\n",
    "    evidence.append(e2)\n",
    "    evidence.append(e3)\n",
    "    a['evidence']=evidence\n",
    "    delta = str(time.time()-start)\n",
    "    a['time']=delta\n",
    "    json_out4.append(a);\n",
    "    \n",
    "    \n",
    "    \n",
    "    #if(cnt%500==0):\n",
    "    if(cnt%2==0):\n",
    "        out = open(outfile,'w')\n",
    "        out.write(json.dumps(json_out, ensure_ascii=False, indent=4))\n",
    "        out.close();\n",
    "        \n",
    "        out4 = open(outfile4,'w')\n",
    "        out4.write(json.dumps(json_out4, ensure_ascii=False, indent=4))\n",
    "        out4.close();\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        print(str(cnt)+\"/\"+str(len(json_data))+\" \"+str(delta)[:4]+\"초\");\n",
    "        print(f\"Question: {query}\")\n",
    "        print(\"Pred_qa: \"+pred_qa);\n",
    "        #print(f\"<입력 문장과 유사한 {top_k} 개의 문장>\")\n",
    "\n",
    "        for i, (score, idx) in enumerate(zip(top_results[0], top_results[1])):\n",
    "            print(f\"[{i+1}] {sentences[idx][0:min(500,len(sentences[idx]))]} {'(유사도: {:.4f})'.format(score)}\")\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d53746e-0df9-498a-af28-645320ac890f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "italian",
   "language": "python",
   "name": "italian"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
